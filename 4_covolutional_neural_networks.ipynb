{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "This notebook is based on my learning from **course 3** of the **Deep Learning Specialization** provided by **deeplearning.ai**. The course videos could be found on [YouTube](https://www.youtube.com/watch?v=ArPaAX_PhIs&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF) or [Coursera](https://www.coursera.org/specializations/deep-learning). Learning through Coursera is highly recommended to get access to the quizes and programmin exercises along the course, as well as the course certification upon completion. Personally, I completed the specialization of 5 coursesand acquired [Specialization Certificate](https://coursera.org/share/e590c28a5c258e500ca6d3ccb4ed57ba). Later, I discovered the YouTube videos and used them for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations of Convolutional Nueral Networks\n",
    "\n",
    "### Edge Detection Examples\n",
    "\n",
    "Earlier layers might detect edges. The somewhat later layers might detect part of the objects, and the even later layers might detect part of the the complete objects.\n",
    "\n",
    "Detect vertical edge in a 6 by 6 image (the $*$ sign means convolution):\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "3 & 0 & 1 & 2 & 7 & 4 \\\\\n",
    "1 & 5 & 8 & 9 & 3 & 1 \\\\\n",
    "2 & 7 & 2 & 5 & 1 & 3 \\\\\n",
    "0 & 1 & 3 & 1 & 7 & 8 \\\\\n",
    "4 & 2 & 1 & 6 & 2 & 8 \\\\\n",
    "2 & 4 & 5 & 2 & 3 & 9 \\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "-5 & -4 & 0 & 8 \\\\\n",
    ". & . & . & . \\\\\n",
    ". & . & . & . \\\\\n",
    ". & . & . & . \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $3\\times1 + 1\\times1 + 2\\times1 + 0\\times0 + 5\\times0 + 7\\times0 + 1\\times-1 + 8\\times-1 + 2\\times-1 = -5$\n",
    "- and so on\n",
    "\n",
    "```pyhon\n",
    "tf.nn.conv2D\n",
    "```\n",
    "When there's a vertical line in the image:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "10 & 10 & 10 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "0 & 30 & 30 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### More Edge Detection\n",
    "\n",
    "Horizontal edge: $\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -1 & -1 \\\\\n",
    "\\end{bmatrix}$, Sobel filter: $\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -1 \\\\\n",
    "2 & 0 & -2 \\\\\n",
    "1 & 0 & -1 \\\\\n",
    "\\end{bmatrix}$, Scharr filter: $\n",
    "\\begin{bmatrix}\n",
    "3 & 0 & -3 \\\\\n",
    "10 & 0 & -10 \\\\\n",
    "3 & 0 & -3 \\\\\n",
    "\\end{bmatrix}$, or learn the nine parameters by backprobagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "Valid convolutions (without padding): \n",
    "\n",
    "- $(n, n) * (f, f) = (n-f+1, n-f+1)$\n",
    "\n",
    "- $(6,6) * (3,3) = (4,4)$\n",
    "\n",
    "\n",
    "Same convolutions (pad so that output size is the same as the input size); (padding with $p=1$ in this example): \n",
    "\n",
    "- $(n+2p, n+2p) * (f, f) = (n+2p-f+1, n+2p-f+1)$\n",
    "\n",
    "- $(8,8) * (3,3) = (6,6)$\n",
    "\n",
    "- $f$ is uaually odd\n",
    "\n",
    "- when $f=5, p=2$ for same conlutions\n",
    "\n",
    "\n",
    "### Strided Convolutions\n",
    "\n",
    "When stride = 2, take 2 steps instead of 1 step.\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "2 & 3 & 7 & 4 & 6 & 2 & 9 \\\\\n",
    "6 & 6 & 9 & 8 & 7 & 4 & 3 \\\\\n",
    "3 & 4 & 8 & 3 & 8 & 9 & 7 \\\\\n",
    "7 & 8 & 3 & 6 & 6 & 3 & 4 \\\\\n",
    "4 & 2 & 1 & 8 & 3 & 4 & 6 \\\\\n",
    "3 & 2 & 4 & 1 & 9 & 8 & 3 \\\\\n",
    "0 & 1 & 3 & 9 & 2 & 1 & 4 \\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "3 & 4 & 4 \\\\\n",
    "1 & 0 & 2 \\\\\n",
    "-1 & 0 & 3 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "91 & 100 & 93 \\\\\n",
    "69 & 91 & 127 \\\\\n",
    "44 & 72 & 74 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $(n+2p, n+2p) * (f, f) = (\\lfloor\\frac{n+2p-f}{s}+1\\rfloor, \\lfloor\\frac{n+2p-f}{s}+1\\rfloor)$\n",
    "- If the output is not an iteger, we round down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions over Volumes\n",
    "\n",
    "**When there're multiple channels.**\n",
    "\n",
    "More details: [video](https://www.youtube.com/watch?v=KTB_OFoAQcc&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=6).\n",
    "\n",
    "- $(6, 6, 3) * (3, 3, 3) = (4, 4)$ The channel $3$ in $(6, 6, 3)$ has to be the same in both image and filter.\n",
    "- We can use the filter to detect a certain color or  all colors\n",
    "- We can apply multiple filters and then stack the output as new channels\n",
    "- **Number of filters will become the new number of channels.**\n",
    "- Summary: $(n, n, n_c) * (f, f, n_c) = (n-f+1, n-f+1, n_c')$\n",
    "\n",
    "### One Layer of a COnvolutional Net\n",
    "\n",
    "If you have 10 filters that are 3 x 3 x 3 in one layer of a neural network, how many parameters does that layers have?\n",
    "- Each filter: 3x3x3 + 1 = 28\n",
    "- All filters: 28x10 = 280\n",
    "\n",
    "If layer $l$ is a convolution layer:\n",
    "- $f^{[l]} =$ filter size\n",
    "- $p^{[l]} =$ padding\n",
    "- $s^{[l]} =$ stride\n",
    "- $n_c^{[l]} =$ number of filters\n",
    "\n",
    "\n",
    "- Each filter is: $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]}$\n",
    "\n",
    "\n",
    "- Activations: $a^{[l]} \\rightarrow n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]}$\n",
    "\n",
    "\n",
    "- Weights: $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times n_c^{[l]}$\n",
    "\n",
    "\n",
    "- Bias: $n_c^{[l]} = (1, 1, 1, n_c^{[l]})$\n",
    "\n",
    "\n",
    "- Input: $n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_C^{[l-1]}$\n",
    "\n",
    "\n",
    "- Output: $n_H^{[l]} \\times n_W^{[l]} \\times n_C^{[l]}$\n",
    "\n",
    "\n",
    "-  $n_H^{[l]} = \\lfloor \\frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1\\rfloor, n_W^{[l]} = ...$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layers\n",
    "\n",
    "Break the input into different regions and take the max of each region.\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & 3 & 2 & 1 \\\\\n",
    "2 & 9 & 1 & 1 \\\\\n",
    "1 & 3 & 2 & 3 \\\\\n",
    "5 & 6 & 1 & 2 \\\\\n",
    "\\end{bmatrix} \\rightarrow \\begin{bmatrix}\n",
    "9 & 2 \\\\\n",
    "6 & 3 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Hyperparameters $f=2, s=2$\n",
    "\n",
    "Intuition: A large number might mean a particular feature. What max pooling does is to detect the feature. However, no one can really say how it works for sure. Max pooling just works well in a lot of experiments/literatures.\n",
    "\n",
    "Also: average pooling - used less often\n",
    "\n",
    "Hypterparamters:\n",
    "- $f$: filter size\n",
    "- $s$: stride\n",
    "- Max or average pooling\n",
    "\n",
    "No parameters/weights to learn, so usually it's not considered a real layer.\n",
    "\n",
    "$n_H \\times n_W \\times n_C \\rightarrow \\lfloor \\frac{n_H-f}{s} + 1 \\rfloor \\times \\lfloor \\frac{n_W-f}{s} + 1 \\rfloor \\times n_C$\n",
    "\n",
    "### CNN Example\n",
    "\n",
    "| Layer | Activation shape | Activation Size | # parameters |\n",
    "| --- | --- | --- | --- |\n",
    "| Input | (32, 32, 3) | 3072 | 0 |\n",
    "| CONV1 (f=5, s=1) | (28, 28, 8) | 6272 | 208 |\n",
    "| POOL1 | (14, 14, 8) | 1568 | 0 |\n",
    "| CONV2 (f=5, s=1) | (10, 10, 16) | 1600 | 416 |\n",
    "| POOL2 | (5, 5, 16) | 400 | 0 |\n",
    "| FC3 | (120, 1) | 120 | 48001 |\n",
    "| FC4 | (84,1) | 84 | 10081 |\n",
    "| Softmax | (10,1) | 10 | 841 |\n",
    "\n",
    "\n",
    "### Why Convolutions\n",
    "\n",
    "Paramater sharing: A featrue detector (such as a vertical edge detector) that's useful in one part of the image is probably useful in another part of the image.\n",
    "\n",
    "Sparsity of connections: In each layer, each output value depends only on a small number of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Models: Case Studies\n",
    "\n",
    "Classic networks:\n",
    "- LeNet-5\n",
    "- AlexNet\n",
    "- VGG\n",
    "\n",
    "ResNet\n",
    "\n",
    "Inception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
