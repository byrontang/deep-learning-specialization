{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\n",
    "\n",
    "This notebook is based on my learning from **course 2** of the **Deep Learning Specialization** provided by **deeplearning.ai**. The course videos could be found on [YouTube](https://www.youtube.com/watch?v=1waHlpKiNyY&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc) or [Coursera](https://www.coursera.org/specializations/deep-learning). Learning through Coursera is highly recommended to get access to the quizes and programmin exercises along the course, as well as the course certification upon completion. Personally, I completed the specialization of 5 coursesand acquired [Specialization Certificate](https://coursera.org/share/e590c28a5c258e500ca6d3ccb4ed57ba). Later, I discovered the YouTube videos and used them for review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Practical Aspects of Deep Learning\n",
    "\n",
    "### Test/Dev/Test Sets\n",
    "- Applying DL is a very iterative process to find the best hyperparameters.\n",
    "- Split dataset\n",
    "    - Previous era: 70/30 or 60/20/20 (n <= 100,000)\n",
    "    - Big data: 98/1/1 (n >= 1,000,000) 10,000 samples might be enough for test set; 99.5/ .4/ .1 for even bigger dataset\n",
    "- Beware of mismatched train/test distribution\n",
    "- It might be ok to not have the test set\n",
    "\n",
    "### Bias/Variance\n",
    "- High variance: overfitting the data (low bias in training but high bias in test)\n",
    "- High bias: underfitting the data compared to baseline (human judgement) (high bias in both training and testing)\n",
    "- High bias and high variance (high bias in training and even worse in test)\n",
    "- Low bias and low variance: a really good model (low bias in both training and test)\n",
    "\n",
    "### Basic Receip\n",
    "1. High bias? (training data performance) -> Bigger network, train longer, NN architecture search\n",
    "2. High variance? (dev set performance) -> More data, regularization, NN architecture search\n",
    "\n",
    "Bias/variance tradeoff is not always the case for DL if appropriate techiniques (ex: bigger network and more data) are selected.\n",
    "\n",
    "### Regularization (might introduce bias/viariance tradeoff)\n",
    "\n",
    "- L2 regularization is used much more often than L1 when training NN models.\n",
    "- $\\lambda$ is the regularization parameter\n",
    "- In Neural Network:\n",
    "\n",
    "$J(\\mathbf{w}, \\mathbf{b}) = \\frac{1}{m}\\sum_{i=1}^{n}L(\\hat{y},y) +$<font color='blue'>$\\frac{\\lambda}{2m}\\sum_{l=1}^{L}||\\mathbf{w}^{[l]}||^2_F$</font>\n",
    "\n",
    "<font color='blue'>$\\text{Frobenius norm (L2 norm)}: ||\\mathbf{w}^{[l]}||^2_F = \\sum_{i=1}^{n^{[l-1]}}\\sum_{i=1}^{n^{[l]}}(w^{[l]}_{ij})^2$</font>, $\\mathbf{w}^{[l]}: (n^{[l-1]}, n^{[l]})$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial w^{[l]}} =  \\mathbf{dw}^{[l]}, \\mathbf{dw}^{[l]} = \\frac{1}{m}\\mathbf{dZ}^{[l]} \\mathbf{A}^{[l-1]} +$ <font color='blue'>$\\frac{\\lambda}{m}\\mathbf{w}^{[l]} $</font>\n",
    "\n",
    "- With large $\\lambda$, we are telling the model to get smaller $\\mathbf{w}$. This would encourage the training process to return a simpler model, which is like having a smoother boundary between classes if visualized. \n",
    "\n",
    "### Dropout Regularization\n",
    "\n",
    "- In each iteration, randomly eliminate nodes at each layer to get a smaller, more diminished notes.\n",
    "- Implementation - inverted dropout\n",
    "```python\n",
    "keep-prob = 0.8\n",
    "d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep-prob\n",
    "a3 = np.multiply(a3, d3) \n",
    "a3 /= keep-prob # Correct the expected value z in z=wa+b\n",
    "```\n",
    "#### Notes:\n",
    "    1. **After adjusting the value of a, we still train w and b properly.**\n",
    "    2. **With dropout, different set of w and b are trained in each iteration so that overall the w and b are not over-trained.**\n",
    "    3. **Matrix a is dropped out instead of w. We still have all w when training the model.**\n",
    "\n",
    "\n",
    "- Making prediction at test time\n",
    "    - Not to use drop out\n",
    "    \n",
    "- Intuition: Can't rely on any one feature, so have to spread out weights. -> Shingking the weights, similar effect of L2 regularization\n",
    "- Higher keep-prob on smaller layers; No need to use keep-prob on all layers\n",
    "- Dropout is frequently used in computer vision\n",
    "- Downside: Cost function $J$ is less well-defined\n",
    "\n",
    "#### More Regularization Methods\n",
    "- Data augmentation\n",
    "- Early stopping\n",
    "\n",
    "#### Weight Initialization\n",
    "\n",
    "With large n (notes in each layer), we want smaller w.\n",
    "\n",
    "$\\text{ReLU: Var}(\\mathbf{w}^{[l]}) = \\frac{2}{n^{[l-1]}}$\n",
    "\n",
    "$\\text{tanh: Var}(\\mathbf{w}^{[l]}) = \\sqrt{\\frac{1}{n^{[l-1]}}}$\n",
    "\n",
    "```python\n",
    "\n",
    "w_l = np.random.rand(shape) * np.sqrt(1/n_previous_l)\n",
    "```\n",
    "\n",
    "However, in practice, tuning the weight in this way is usually less important compared to other tuning techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimization Algorithms\n",
    "\n",
    "### Mini Batch Gradient Descent\n",
    "- Notation: $X^{\\{t\\}}, Y^{\\{t\\}}$\n",
    "- 1 epoch = a round of t mini batch gradient descent\n",
    "\n",
    "Benefit:\n",
    "- Reduce training time\n",
    "- Make progress quickly\n",
    "\n",
    "Compare mini-batch size:\n",
    "- If mini-batch size = $m$: **Batch gradient descent**\n",
    "    - Too long per iteration\n",
    "- If mini-batch size = 1: **Stochastic gradient descent**\n",
    "    - Inefficient; lose speed from vactorization\n",
    "- In practice: somewhere between 1 and $m$\n",
    "    - Fastest learning with vectorization (~1000)\n",
    "    - Make progress without processing entire training set\n",
    "\n",
    "Choose mini-batch size:\n",
    "- If small training set: use batch gradient descent\n",
    "    - m less than 2000\n",
    "- Typical mini-batch sizes: 64, 128, 256, 512\n",
    "- Make sure minibatch fit in CPU/GPU memory\n",
    "\n",
    "### Exponentially Weighted Averages\n",
    "\n",
    "Data: $[\\theta_1, \\theta_2, ... \\theta_t]$\n",
    "\n",
    "- $V_0 = 0$\n",
    "- $V_2 = \\beta V_0 + (1-\\beta) \\theta_1$\n",
    "- ...\n",
    "- $V_t = \\beta V_t-1 + (1-\\beta) \\theta_t$ (The equation for exponentially weighted averages)\n",
    "\n",
    "$V_t$ as approximally average over $\\approx \\frac{1}{1-\\beta}$ days' data.\n",
    "- $\\beta = 0.9 :\\approx 10$ days' data\n",
    "- $\\beta = 0.98 :\\approx 50$ days' data\n",
    "\n",
    "More about the equation\n",
    "\n",
    "$$V_t = (1-\\beta) \\theta_t + \\beta V_t-1$$ \n",
    "$$= (1-\\beta) \\theta_t + (1-\\beta) \\times \\beta \\times \\theta_{t-1} + (1-\\beta) \\times (\\beta)^2 \\times \\theta_{t-2} + (1-\\beta) \\times (\\beta)^3 \\times \\theta_{t-3} + ...$$\n",
    "\n",
    "$(1-\\varepsilon)^{\\frac{1}{\\varepsilon}} = \\frac{1}{e} \\approx 0.35$: It takes about $(1-\\beta)$ for the weight to decay to $\\frac{1}{3}$.\n",
    "\n",
    "### Bias Correction of Exponentially Weighted Averages\n",
    "\n",
    "Modify the bias due to $V_0 = 0$:\n",
    "\n",
    "Use $\\frac{V_t}{1-\\beta^{t}}$ instead of $V_t$\n",
    "\n",
    "Example:\n",
    "\n",
    "$t=2: 1-\\beta^{t} = 1 (0.98)^2 = 0.0396$\n",
    "\n",
    "$\\frac{V_2}{0.0396} = \\frac{0.0196\\theta_1 + 0.02\\theta_2}{0.0396}$ The denominator is the original value before correction.\n",
    "\n",
    "\n",
    "### Gradient Descent with Momentum\n",
    "\n",
    "**Compute exponentially weighted averages of the gradients and then use them to update the gradients.** Conceptially, it averages out the oscillations of gradients in previous steps.\n",
    "\n",
    "$\\mathbf{V}_{dw} = 0, \\mathbf{V}_{db} = 0$\n",
    "\n",
    "On iteration $t$:\n",
    "\n",
    "{\n",
    "\n",
    "Compute $dw, db$ on current mini-batch\n",
    "\n",
    "$\\mathbf{V}_{dw} = \\beta \\mathbf{V}_{dw} + (1-\\beta)\\mathbf{dw}$\n",
    "\n",
    "$\\mathbf{V}_{db} = \\beta \\mathbf{V}_{db} + (1-\\beta)\\mathbf{db}$\n",
    "\n",
    "$\\mathbf{w} := \\mathbf{w}-\\alpha \\mathbf{V}_{dw}, \\mathbf{b}:=\\mathbf{b}-\\alpha \\mathbf{v}_{db}$\n",
    "\n",
    "}\n",
    "\n",
    "Hyperparameters: $\\alpha, \\beta$\n",
    "\n",
    "$\\beta = 0.9$ is the most common value, which approximately averages last 10 gradients. In practice, it works very well. ALso, in practice people don't bother using bias correction $\\frac{V_t}{1-\\beta^{t}}$ and just wait until the bias is gone after the first few iterations.\n",
    "\n",
    "#### Note: There's only one set of $v_{dw}$ and $v_{db}$ for each neuron at a time. The value of $\\mathbf{V}_{dw}$ and $\\mathbf{V}_{db}$ are updated after training each mini-batch based on $v_\\theta = \\beta v_\\theta + (1-\\beta)\\theta_t$. We only care about the result from the previous mini-batch instead of all mini-batches.\n",
    "\n",
    "\n",
    "### RMSProp\n",
    "\n",
    "On iteration $t$:\n",
    "\n",
    "{\n",
    "\n",
    "Compute $dw, db$ on current mini-batch.\n",
    "\n",
    "$\\mathbf{S}_{dw} = \\beta_2 \\mathbf{S}_{dw} + (1-\\beta_2)\\mathbf{dw}^2$\n",
    "\n",
    "$\\mathbf{S}_{db} = \\beta_2 \\mathbf{S}_{db} + (1-\\beta_2)\\mathbf{db}^2$\n",
    "\n",
    "$\\mathbf{w} := \\mathbf{w}-\\alpha \\frac{\\mathbf{dw}}{\\sqrt{\\mathbf{S}_{dw}+\\varepsilon}}, \\mathbf{b} := \\mathbf{b}-\\alpha \\frac{\\mathbf{db}}{\\sqrt{\\mathbf{S}_{db}+\\varepsilon}}$\n",
    "\n",
    "}\n",
    "\n",
    "$\\varepsilon = 10^{-8}$ or a very small number to make sure $dw$ and $db$ are not divided by 0.\n",
    "\n",
    "Intuitively, It will make the gradient moving faster on the directions that require larger movement and slower on directions that requires less movement.\n",
    "\n",
    "\n",
    "### Adam Optimization Algorithm\n",
    "\n",
    "**Combine momentum and RMSProp**\n",
    "\n",
    "$\\mathbf{V}_{dw} = 0, \\mathbf{S}_{dw} = 0, \\mathbf{V}_{db} = 0, \\mathbf{S}_{db} = 0$\n",
    "\n",
    "On iteration $t$:\n",
    "\n",
    "{\n",
    "\n",
    "Compute $dw, db$ on current mini-batch\n",
    "\n",
    "Momentum:\n",
    "\n",
    "$\\mathbf{V}_{dw} = \\beta_1 \\mathbf{V}_{dw} + (1-\\beta_1)\\mathbf{dw}, \\mathbf{V}_{db} = \\beta_1 \\mathbf{V}_{db} + (1-\\beta_1)\\mathbf{db}$\n",
    "\n",
    "RMSProp:\n",
    "\n",
    "$\\mathbf{S}_{dw} = \\beta_2 \\mathbf{S}_{dw} + (1-\\beta_2)\\mathbf{dw}^2, \\mathbf{S}_{db} = \\beta_2 \\mathbf{S}_{db} + (1-\\beta_2)\\mathbf{db}^2$\n",
    "\n",
    "Bias correction:\n",
    "\n",
    "$\\mathbf{V}_{dw}^{corrected} = \\mathbf{V}_{dw} / (1-\\beta_1^t), \\mathbf{V}_{db}^{corrected} = \\mathbf{V}_{db} / (1-\\beta_1^t)$\n",
    "\n",
    "$\\mathbf{S}_{dw}^{corrected} = \\mathbf{S}_{dw} / (1-\\beta_2^t), \\mathbf{S}_{db}^{corrected} = \\mathbf{S}_{db} / (1-\\beta_2^t)$\n",
    "\n",
    "$\\mathbf{w} := \\mathbf{w}-\\alpha \\frac{\\mathbf{V}_{dw}^{corrected}}{\\sqrt{\\mathbf{S}_{dw}^{corrected}+\\varepsilon}}, \\mathbf{b} := \\mathbf{b}-\\alpha \\frac{\\mathbf{V}_{db}^{corrected}}{\\sqrt{\\mathbf{S}_{db}^{corrected}+\\varepsilon}}$\n",
    "\n",
    "}\n",
    "\n",
    "Hyperparameters: \n",
    "- $\\alpha$: needs to be tuned\n",
    "- $\\beta_1 \\rightarrow dw$: 0.9 recommended; no need to tune; first moment\n",
    "- $\\beta_2 \\rightarrow dw^2$: 0.999 recommended; no need to tune; second moment\n",
    "- $\\varepsilon$: $10^{-8}$ recommended; no need to tune\n",
    "\n",
    "Adam: Adoptive Moment Estimation\n",
    "\n",
    "\n",
    "### Learning Rate Decay\n",
    "\n",
    "**Slowly reduce learning rate overtime**\n",
    "\n",
    "Ituition: Sometimes the weights might never converge. Reducing alpha helps the weight to converge as it approches the minimum by taking smaller steps.\n",
    "\n",
    "1 epoch = 1 pass throught the data\n",
    "\n",
    "$$\\alpha = \\frac{1}{1 + \\text{decay rate} \\times \\text{epoch number}}\\alpha_0$$\n",
    "\n",
    "The decay rate becomes another hyperparameter that we need to tune along with $\\alpha_0$.\n",
    "\n",
    "Other learning rate decay methods:\n",
    "\n",
    "- $\\alpha = 0.95^{\\text{epoch number}}\\alpha_0$\n",
    "\n",
    "- $\\alpha = \\frac{k}{\\sqrt{\\text{epoch number}}}\\alpha_0$ or $\\frac{k}{\\sqrt{t}}\\alpha_0$, where $k$ is a constant and $t$ is mini-batch number\n",
    "\n",
    "- Discrete staircase\n",
    "\n",
    "- Manual decay\n",
    "\n",
    "Learning rate decay is usually lower down on the list to try. Choosing $\\alpha$ well would really make a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning, Batch Normalization, and Programming Frameworks\n",
    "\n",
    "### Tuning Process\n",
    "\n",
    "Piority\n",
    "- $\\alpha$: most important\n",
    "- $\\beta, \\text{# hidden units}, \\text{mini-batch size}$: second important\n",
    "- $\\text{# layers},  \\text{learning rate decay}$: third important\n",
    "- $\\beta_1, \\beta_2, \\varepsilon$: only use default\n",
    "\n",
    "Parameter Sampling:\n",
    "- Try random values: don't use a grid.\n",
    "- Course to fine.\n",
    "\n",
    "### Use appropriate scale\n",
    "- $\\alpha$: randomly sample at log scale\n",
    "\n",
    "### Hyperparameter Tuning in Practice\n",
    "- Intuition of hyperparameter setting from one application area may or may not transfer to a different one.\n",
    "- Intuitions do get stale. Re-evaluate occasionally.\n",
    "- Babysitting one model when there's not a lot of compute resource vs. Training many models in parallel\n",
    "\n",
    "### Nomalizing Activations in a Network\n",
    "Not just normalize $X$ but $Z^{[n]}$ as well.\n",
    "\n",
    "Given some intermediant values in NN $z^{(i)}, ..., z^{(m)}$\n",
    "\n",
    "{\n",
    "\n",
    "$\\mu = \\frac{1}{m}\\sum_{i}z{(i)}$\n",
    "\n",
    "$\\sigma^2 = \\frac{1}{m}\\sum_{i}(z_i-\\mu)^2$\n",
    "\n",
    "$z_norm^{(i)} = \\frac{z^{(i)}-\\mu}{\\sqrt{\\mu^2+\\varepsilon}}$\n",
    "\n",
    "- $\\varepsilon$ is added here just in case $\\mu$ turns out to be 0.\n",
    "\n",
    "$\\tilde{z^{(i)}} = \\gamma z_{norm}^{(i)} + \\beta$\n",
    "\n",
    "$\\gamma$ and $\\beta$ are learnable parameters of model.\n",
    "\n",
    "- We don't always want $\\tilde{z^{(i)}}$ to be normally distributed. If $\\gamma = \\sqrt{\\mu^2+\\varepsilon}, \\beta = \\mu$, then $\\tilde{z^{(i)}} = z^{(i)}$\n",
    "\n",
    "Use $\\tilde{\\mathbf{z}^{[l](i)}}$ instead of $\\mathbf{z}^{[l](i)}$\n",
    "\n",
    "}\n",
    "\n",
    "### Fitting Batch Norm Into Neural Networks\n",
    "\n",
    "$\\mathbf{Z}^{[l]} = \\mathbf{w}^{[l]}\\mathbf{A}^{[l-1]}$ \n",
    "\n",
    "- $\\mathbf{b}^{[l]}$ has no impact will have no impact on $\\tilde{\\mathbf{Z}}^{[l]}$ since we're going to  after subtracted $\\mathbf{Z}^{[l]}$ by mean.\n",
    "\n",
    "Compute $\\mathbf{Z}_{norm}^{[l]}$\n",
    "\n",
    "$\\tilde{\\mathbf{Z}}^{[l]} = \\gamma \\mathbf{Z}_norm^{[l]} + \\mathbf{\\beta}^{[l]}$\n",
    "\n",
    "$\\mathbf{A}^{[l]} = g^{[l]}(\\tilde{\\mathbf{Z}}^{[l]})$ \n",
    "\n",
    "Parmeters: $\\mathbf{w}^{[l]}, \\mathbf{\\beta}^{[l]}, \\mathbf{\\gamma}^{[l]}$\n",
    "\n",
    "- $\\mathbf{b}^{[l]}$ is not a parater any more. It is replace by $\\mathbf{\\beta}^{[l]}$.\n",
    "- $\\mathbf{\\beta}^{[l]}$ here is different form the $\\beta$ used for momentum or Adam.\n",
    "- The shape of $\\mathbf{\\beta}^{[l]}$ and $\\mathbf{\\gamma}^{[l]}$ is also $(n^{[l]}, 1)$.\n",
    "\n",
    "$\\mathbf{w}^{[l]}:=\\mathbf{w}^{[l]}-\\alpha\\mathbf{dw}^{[l]}$\n",
    "\n",
    "$\\mathbf{\\beta}^{[l]}:=\\mathbf{\\beta}^{[l]}-\\alpha\\mathbf{d\\beta}^{[l]}$ \n",
    "\n",
    "$\\mathbf{\\gamma}^{[l]}:=\\mathbf{\\gamma}^{[l]}-\\alpha\\mathbf{d\\gamma}^{[l]}$ \n",
    "\n",
    "- We can also use optimization algorithms like Adam to compute $\\mathbf{\\beta}^{[l]}$\n",
    "\n",
    "```python\n",
    "tf.nn.batch-normalization\n",
    "```\n",
    "\n",
    "In practice, batch norm is usually applied with mini-batches in training set. Only normalize the mini-batch with the data/output of the same mini-batch.\n",
    "\n",
    "### Why does Batch Norm Work?\n",
    "\n",
    "1. Speeds up learning just as normalization of input $X$.\n",
    "\n",
    "2. Makes weights later in deep NN more robust than weights earlier in NN. Covariate shift.\n",
    "    - No matter how the value of $\\mathbf{A}^{[l-1]}$ changes, it will always have mean 0 and variance 1 (or any other mean and varisou), so that it limits the amount how the updates of previous $\\mathbf{w}$ and$ \\mathbf{b}$ would affect the distribution of $\\mathbf{A}^{[l-1]}$ that layer $l$ will see and used to train $\\mathbf{w}^{[l]}, \\mathbf{b}^{[l]}$. $\\mathbf{A}$ becomes more stable and later layers don't have to adopt as much to the changes of former layers. Each layer learn more independently from other layers.\n",
    "    \n",
    "3. Batch norm as regularization.\n",
    "    - Each mini-batch is scaled by the mean/variance computed on just that mini-batch.\n",
    "    - This adds some **noise** to the values $z^{[l]}$ within that minibatch. (The mean and variance calculated by the mini-batch are not the true mean and variance.) So similar to dropout, it adds some niose to each hidden layer's activations.\n",
    "    - This has a **slight** regularization effect. Using a larger mini-batch could reduce the noise and therefore the regularization effect.\n",
    "    - This is just an unintended side effect. However, do not consider batch norm as a regularization tool.\n",
    "\n",
    "### Batch Norm at Test Time\n",
    "\n",
    "In training, the $\\mu$ and $\\sigma^2$ are calculated in each mini-batch:\n",
    "\n",
    "$\\mu = \\frac{1}{m}\\sum_{i}z^{(i)}$\n",
    "\n",
    "$\\sigma^2 = \\frac{1}{m}\\sum_{i}(z^{(i)}-\\mu)^2$\n",
    "\n",
    "However, in testing, it might be impractical since there could be only 1 testing sample in each mini-batch. Therefore, we use weighted average across mini-batches to calculate $\\mu$ and $\\sigma^2$: keep track of the $\\mu$ and $\\sigma^2$ value and update the values by weighted average in each mini-batch.\n",
    "\n",
    "Then use the following to get $z_{norm}^{(i)}$ and $\\tilde{z}^{(i)}$\n",
    "$z_{norm} = \\frac{z-\\mu}{\\sqrt{\\mu^2+\\varepsilon}}$\n",
    "\n",
    "$\\tilde{z} = \\gamma z_{norm} + \\beta$\n",
    "\n",
    "\n",
    "### Softmax Regression\n",
    "\n",
    "**Make prediction for multi-class classification.**\n",
    "\n",
    "The probabilities of all output should be summed to 1.\n",
    "\n",
    "In final layer $L$:\n",
    "\n",
    "{\n",
    "\n",
    "$\\mathbf{z}^{[L]} = \\mathbf{w}^{[L]}\\mathbf{a}^{[L-1]} + \\mathbf{b}^{[L]}$\n",
    "\n",
    "Activation function: \n",
    "- $\\mathbf{t} = e^{\\mathbf{z}^{[L]}}$ \n",
    "- $\\mathbf{a}^{[L]} = \\frac{\\mathbf{t}}{\\sum \\mathbf{t}}$\n",
    "\n",
    "The shape of $\\mathbf{z}^{[L]}$ = the shape of $\\mathbf{t}$ = the shape of $\\mathbf{a}^{[L]}$ = $(C,1)$, where $C=$ number of classes\n",
    "\n",
    "}\n",
    "\n",
    "Softmax activation takes in vector inputs and generate vector outputs as compared to other activation functions that can take a single number as an input.:\n",
    "\n",
    "$\\mathbf{a}^{[L]} = g^{[L]}(\\mathbf{z}^{[L]})$\n",
    "\n",
    "Hardmax only look at the vector $\\mathbf{a}^{[L]}$ and assign 1 to the highest number and 0 to the others.\n",
    "\n",
    "### Training Softmax Classifier\n",
    "\n",
    "**Loss function:**\n",
    "\n",
    "$L(\\hat{y}, y) = -\\sum_{j=1}^{4}y_jlog\\hat{y}_j$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "$y = \\begin{bmatrix}\n",
    "        0 \\\\\n",
    "        1 \\\\\n",
    "        0 \\\\\n",
    "        0\\\\ \n",
    "        \\end{bmatrix}$\n",
    "        \n",
    "$\\hat{y} = \\begin{bmatrix}\n",
    "            0.3 \\\\\n",
    "            0.2 \\\\\n",
    "            0.1 \\\\\n",
    "            0.4\\\\ \n",
    "            \\end{bmatrix}$\n",
    "\n",
    "$L(\\hat{y}, y) = -\\sum_{j=1}^{4}y_jlog\\hat{y}_j = -log\\hat{y}_2 \\rightarrow $ make $\\hat{y}_2$ as big as possible.\n",
    "\n",
    "**Cost function:**\n",
    "\n",
    "$J(\\mathbf{w}, \\mathbf{b}) = \\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i)}) $\n",
    "\n",
    "$\\mathbf{Y}$ and $\\hat{\\mathbf{Y}}$ will be a $(C, m)$ matrix.\n",
    "\n",
    "**Backpropagation:**\n",
    "\n",
    "$\\mathbf{dz}^{[L]} = \\frac{\\partial J}{\\partial \\mathbf{z}^{[L]}}$\n",
    "\n",
    "Deep learning programming framework (such as TensorFlow) will take care of the derivative compuation.\n",
    "\n",
    "### The Problem of Local Optima\n",
    "\n",
    "Most of the local optimas are saddle points. \n",
    "- Unlikely to get stuck in a bad local optima\n",
    "- Plateaus can really can make learning slow. -> speed up by optimizations like Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "Use TensorFlow to minimize $J(w) = w^2 - 10w + 25$ and get $w = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# w is the variable we want to optimize\n",
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "# The formula creates computation graph under the hood (backwoard functions are automatically done)\n",
    "#cost = tf.add(tf.add(w**2, tf.multiply(-10., w)), 25)\n",
    "cost = w**2 - 10*w + 25\n",
    "\n",
    "# We can also use other optimization methods like Adam\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing the concept of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "coefficient = np.array([[1.], [-10.], [25.]])\n",
    "\n",
    "# Get training data into the function\n",
    "x = tf.placeholder(tf.float32, [3,1])\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.099999994\n"
     ]
    }
   ],
   "source": [
    "session.run(train, feed_dict={x:coefficient}) # feed different x in mini-batches\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9999886\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficient})\n",
    "print(session.run(w))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
